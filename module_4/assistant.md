# üî¨ AI Research Assistant

> **Transform any research topic into a comprehensive, multi-perspective report using AI-powered analyst teams**

A sophisticated multi-agent system that creates specialized AI analysts, conducts parallel research interviews, and generates professional reports with proper citations. Think of it as your personal research team that never sleeps!

---

## üéØ What Does This Do?

### For Non-Technical Users
Imagine you want to research "The Future of Electric Vehicles." Instead of spending hours searching and reading dozens of articles yourself, this system:

1. **Creates Expert Analysts** - Generates 3-5 specialized AI researchers (e.g., Battery Technology Expert, Market Analyst, Environmental Impact Specialist)
2. **Conducts Research** - Each analyst automatically searches the web and Wikipedia, then conducts detailed interviews with AI experts
3. **Writes Professional Reports** - Combines all findings into a polished report with proper citations and sources

**Input:** `"The Future of Electric Vehicles"`  
**Output:** A 2-3 page professional research report covering multiple perspectives with 15+ cited sources

### For Technical Users
A **LangGraph-based multi-agent research system** featuring:
- Parallel agent execution using Send() API
- Human-in-the-loop feedback mechanisms  
- Structured output with Pydantic validation
- Multi-source information retrieval (Web + Wikipedia)
- Dynamic conversation routing and state management
- Automatic citation management and report synthesis

---

## üöÄ Quick Start

### Prerequisites
```bash
pip install langchain langchain-community langchain-openai langgraph pydantic
```

### Environment Setup
```bash
export OPENAI_API_KEY="your-openai-api-key"
export TAVILY_API_KEY="your-tavily-api-key"  # For web search
```

### Basic Usage
```python
# Initialize the research system
graph = builder.compile(interrupt_before=['human_feedback'])

# Run research on any topic
result = graph.invoke({
    "topic": "The Future of Renewable Energy",
    "max_analysts": 4,
    "human_analyst_feedback": "approve"
})

print(result["final_report"])
```

---

## üèóÔ∏è System Architecture

### High-Level Flow
```
üìù Topic Input ‚Üí ü§ñ Create Analysts ‚Üí üë§ Human Review ‚Üí üîç Parallel Research ‚Üí üìä Generate Report
```

### Detailed Architecture Diagram

```
                    üéØ START
                       ‚îÇ
                       ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ ü§ñ Create       ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   Analysts      ‚îÇ                       ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
                       ‚îÇ                                ‚îÇ
                       ‚ñº                                ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ
              ‚îÇ üë§ Human        ‚îÇ ‚óÑ‚îÄ‚îÄ ‚è∏Ô∏è INTERRUPT      ‚îÇ
              ‚îÇ   Feedback      ‚îÇ    (Review & Approve) ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
                       ‚îÇ                                ‚îÇ
                       ‚ñº                                ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ
              ‚îÇ üîÄ Route        ‚îÇ                       ‚îÇ
              ‚îÇ   Decision      ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚ùå Not Approved
                       ‚îÇ
                       ‚ñº ‚úÖ Approved
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ     üöÄ PARALLEL EXECUTION        ‚îÇ
         ‚îÇ        (Send() API)             ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚ñº             ‚ñº             ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇAnalyst 1‚îÇ   ‚îÇAnalyst 2‚îÇ   ‚îÇAnalyst N‚îÇ
   ‚îÇüé≠       ‚îÇ   ‚îÇüé≠       ‚îÇ   ‚îÇüé≠       ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ             ‚îÇ             ‚îÇ
         ‚ñº             ‚ñº             ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ     üé§ INTERVIEW SUB-GRAPH           ‚îÇ
   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
   ‚îÇ  ‚îÇ 1Ô∏è‚É£ Ask Question             ‚îÇ    ‚îÇ
   ‚îÇ  ‚îÇ           ‚îÇ                 ‚îÇ    ‚îÇ
   ‚îÇ  ‚îÇ           ‚ñº                 ‚îÇ    ‚îÇ
   ‚îÇ  ‚îÇ 2Ô∏è‚É£ Search Web + Wikipedia   ‚îÇ    ‚îÇ
   ‚îÇ  ‚îÇ           ‚îÇ                 ‚îÇ    ‚îÇ
   ‚îÇ  ‚îÇ           ‚ñº                 ‚îÇ    ‚îÇ
   ‚îÇ  ‚îÇ 3Ô∏è‚É£ Generate Expert Answer   ‚îÇ    ‚îÇ
   ‚îÇ  ‚îÇ           ‚îÇ                 ‚îÇ    ‚îÇ
   ‚îÇ  ‚îÇ           ‚ñº                 ‚îÇ    ‚îÇ
   ‚îÇ  ‚îÇ üîÑ Continue? OR Save        ‚îÇ    ‚îÇ
   ‚îÇ  ‚îÇ           ‚îÇ                 ‚îÇ    ‚îÇ
   ‚îÇ  ‚îÇ           ‚ñº                 ‚îÇ    ‚îÇ
   ‚îÇ  ‚îÇ 4Ô∏è‚É£ Write Section            ‚îÇ    ‚îÇ
   ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ             ‚îÇ             ‚îÇ
         ‚ñº             ‚ñº             ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇüìù Write ‚îÇ   ‚îÇüìù Write ‚îÇ   ‚îÇüìù Write ‚îÇ
   ‚îÇReport   ‚îÇ   ‚îÇIntro    ‚îÇ   ‚îÇConclusion‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ             ‚îÇ             ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ üìã Finalize     ‚îÇ
              ‚îÇ   Report        ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
                    üèÅ END
```

---

## üß† Core Components Explained

### 1. üé≠ Analyst Generation System

**What it does:** Creates specialized AI personas for different aspects of your research topic.

**How it works:**
```python
# Example generated analysts for "Climate Change"
analysts = [
    {
        "name": "Dr. Sarah Chen",
        "role": "Climate Science Researcher", 
        "affiliation": "Environmental Research Institute",
        "description": "Focuses on temperature trends and climate modeling"
    },
    {
        "name": "Michael Torres", 
        "role": "Policy Impact Analyst",
        "affiliation": "Government Relations Firm",
        "description": "Analyzes policy implications and regulatory frameworks"
    }
]
```

**Technical Details:**
- Uses GPT-4 with structured output (Pydantic models)
- Enforces consistent analyst schema
- Supports human feedback loop for analyst modification

### 2. üîç Intelligent Research Engine

**What it does:** Each analyst searches for relevant information and conducts mock interviews.

**Research Sources:**
- üåê **Web Search** (via Tavily API): Current news, articles, reports
- üìö **Wikipedia** (via LangChain): Encyclopedic knowledge, historical context

**Interview Process:**
```
Analyst: "What are the latest breakthroughs in battery technology?"
   ‚Üì (Searches web + Wikipedia)
Expert: "Recent developments include solid-state batteries with 40% higher energy density..." [1][2]
   ‚Üì
Analyst: "How do these compare to current lithium-ion technology?"
   ‚Üì (Searches for comparative data)
Expert: "Solid-state batteries offer improved safety and longevity..." [3][4]
```

### 3. üìä Report Synthesis Engine

**What it does:** Combines all research into a professional, citation-rich report.

**Output Structure:**
```markdown
# The Future of Electric Vehicles

## Introduction
Electric vehicles represent a transformative shift in transportation...

## Insights
### Battery Technology Advances
Recent breakthroughs in solid-state batteries show promise for 40% increased energy density [1]. This technology addresses key limitations of current lithium-ion systems...

### Market Growth Projections  
Industry analysts project 300% growth in EV adoption by 2030 [2][3]...

## Conclusion
The convergence of battery improvements, policy support, and consumer acceptance...

## Sources
[1] Nature Energy Journal - Solid State Battery Research 2024
[2] Bloomberg New Energy Finance - EV Market Report
[3] International Energy Agency - Global EV Outlook
```

---

## üîß Technical Deep Dive

### State Management Architecture

The system uses two interconnected state machines:

#### üèõÔ∏è Main Research State
```python
class ResearchGraphState(TypedDict):
    topic: str                    # "Climate Change Impact on Agriculture"
    max_analysts: int             # 4
    human_analyst_feedback: str   # "approve" | custom feedback
    analysts: List[Analyst]       # [Analyst1, Analyst2, ...]
    sections: List[str]           # Accumulated report sections
    introduction: str             # Generated intro
    content: str                  # Main report body
    conclusion: str               # Generated conclusion
    final_report: str             # Complete assembled report
```

#### üé§ Interview Sub-State  
```python
class InterviewState(MessagesState):
    max_num_turns: int           # 3 (question-answer cycles)
    context: List[str]           # Retrieved documents
    analyst: Analyst             # Current interviewer
    interview: str               # Full conversation transcript
    sections: List[str]          # Generated report section
```

### üîÑ Advanced Routing Logic

#### Interview Flow Control
```python
def route_messages(state, name="expert"):
    """Smart routing based on conversation state"""
    messages = state["messages"]
    max_turns = state.get('max_num_turns', 2)
    
    # Count expert responses
    expert_responses = len([m for m in messages 
                          if isinstance(m, AIMessage) and m.name == name])
    
    # End conditions
    if expert_responses >= max_turns:
        return 'save_interview'
    
    # Check for completion phrase
    last_question = messages[-2]
    if "Thank you so much for your help" in last_question.content:
        return 'save_interview'
        
    return "ask_question"  # Continue interview
```

#### Parallel Execution Control
```python
def initiate_all_interviews(state):
    """Conditional routing for human approval"""
    feedback = state.get('human_analyst_feedback', 'approve')
    
    if feedback.lower() != 'approve':
        return "create_analysts"  # Loop back for regeneration
    else:
        # Parallel execution via Send() API
        return [Send("conduct_interview", {
            "analyst": analyst,
            "messages": [HumanMessage(content=f"Research topic: {state['topic']}")]
        }) for analyst in state["analysts"]]
```

### üß™ Structured Output System

Uses Pydantic models for consistent data validation:

```python
class SearchQuery(BaseModel):
    search_query: str = Field(description="Optimized search query")

class Analyst(BaseModel):
    affiliation: str = Field(description="Primary organization")
    name: str = Field(description="Analyst name")
    role: str = Field(description="Functional role")
    description: str = Field(description="Focus areas and expertise")
    
    @property
    def persona(self) -> str:
        return f"Name: {self.name}\nRole: {self.role}\n..."

class Perspectives(BaseModel):
    analysts: List[Analyst] = Field(description="Complete analyst team")
```

---

## üéõÔ∏è Configuration Options

### Basic Configuration
```python
config = {
    "topic": "Your Research Topic",
    "max_analysts": 4,                    # 2-6 recommended
    "max_num_turns": 3,                   # Questions per interview
    "human_analyst_feedback": "approve"   # Or custom instructions
}
```

### Advanced Customization

#### Custom Analyst Instructions
```python
custom_feedback = """
Focus on technical aspects rather than business implications.
Include at least one analyst specializing in emerging technologies.
Ensure geographical diversity in perspectives.
"""

config["human_analyst_feedback"] = custom_feedback
```

#### Search Behavior Tuning
```python
# Modify search instructions for domain-specific research
search_instructions = SystemMessage(content="""
Generate academic-focused search queries.
Prioritize peer-reviewed sources and research papers.
Include specific technical terminology.
""")
```

---

## üìä Performance & Scalability

### Execution Metrics
- **Setup Time:** ~30 seconds (analyst generation + human review)
- **Research Time:** ~2-4 minutes per analyst (parallel execution)
- **Report Generation:** ~45 seconds
- **Total Runtime:** ~5-7 minutes for 4 analysts

### Resource Usage
```
API Calls per Run:
‚îú‚îÄ‚îÄ Analyst Generation: 1 GPT-4 call
‚îú‚îÄ‚îÄ Per Analyst (√ó4): 6-10 GPT-4 calls
‚îú‚îÄ‚îÄ Web Searches: 8-12 Tavily calls  
‚îú‚îÄ‚îÄ Wikipedia: 4-8 LangChain calls
‚îî‚îÄ‚îÄ Report Synthesis: 3 GPT-4 calls
Total: ~40-55 API calls
```

### Scaling Considerations
- **Horizontal:** Increase `max_analysts` (linear cost scaling)
- **Depth:** Increase `max_num_turns` (exponential quality improvement)
- **Sources:** Add custom retrievers (modular architecture)

---

## üõ†Ô∏è Advanced Usage Patterns

### Custom Source Integration
```python
def search_arxiv(state: InterviewState):
    """Add academic paper search capability"""
    structured_llm = llm.with_structured_output(SearchQuery)
    query = structured_llm.invoke([search_instructions] + state['messages'])
    
    # Custom ArXiv search logic
    papers = arxiv_search(query.search_query, max_results=3)
    formatted_docs = format_arxiv_results(papers)
    
    return {"context": [formatted_docs]}

# Add to interview graph
interview_builder.add_node("search_arxiv", search_arxiv)
interview_builder.add_edge("ask_question", "search_arxiv")
```

### Domain-Specific Analysts
```python
def create_medical_analysts(state: GenerateAnalystsState):
    """Generate medical research specialists"""
    medical_instructions = """
    Create analysts specialized in medical research:
    1. Clinical researcher focusing on patient outcomes
    2. Pharmaceutical expert on drug development
    3. Public health policy specialist
    4. Medical technology innovation analyst
    """
    # Custom analyst generation logic
```

### Multi-Language Support
```python
def create_multilingual_analysts(state: GenerateAnalystsState):
    """Generate analysts for different regions/languages"""
    topic = state['topic']
    
    analyst_instructions_multilingual = f"""
    Create analysts for global perspective on {topic}:
    - North American market analyst
    - European regulatory expert  
    - Asian technology researcher
    - Emerging markets specialist
    """
```

---

## üîç Troubleshooting Guide

### Common Issues

#### 1. **Empty or Poor Quality Reports**
```python
# Check analyst quality
print("Generated analysts:")
for analyst in result["analysts"]:
    print(f"- {analyst.name}: {analyst.description}")

# Verify search results
print("Search context length:", len(result["context"]))
```

**Solutions:**
- Increase `max_num_turns` for deeper interviews
- Provide more specific topic descriptions
- Add custom search sources for niche topics

#### 2. **API Rate Limiting**
```python
# Add retry logic and delays
from tenacity import retry, wait_exponential

@retry(wait=wait_exponential(multiplier=1, min=4, max=10))
def robust_llm_call(messages):
    return llm.invoke(messages)
```

#### 3. **Inconsistent Citations**
```python
# Validate citation format in post-processing
def validate_citations(report_text):
    import re
    citations = re.findall(r'\[(\d+)\]', report_text)
    sources = re.findall(r'^\[(\d+)\]', report_text, re.MULTILINE)
    return len(citations) == len(set(sources))
```

### Debug Mode
```python
# Enable detailed logging
import logging
logging.basicConfig(level=logging.DEBUG)

# Add state inspection
def debug_state(state):
    print(f"Current state keys: {state.keys()}")
    print(f"Analysts count: {len(state.get('analysts', []))}")
    return state

builder.add_node("debug", debug_state)
```

---

## üöÄ Deployment Options

### Local Development
```bash
# Clone repository
git clone https://github.com/your-repo/ai-research-assistant
cd ai-research-assistant

# Install dependencies
pip install -r requirements.txt

# Set environment variables
export OPENAI_API_KEY="your-key"
export TAVILY_API_KEY="your-key"

# Run
python research_assistant.py
```

### Docker Deployment
```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["python", "research_assistant.py"]
```

### API Server
```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class ResearchRequest(BaseModel):
    topic: str
    max_analysts: int = 4

@app.post("/research")
async def conduct_research(request: ResearchRequest):
    result = graph.invoke({
        "topic": request.topic,
        "max_analysts": request.max_analysts,
        "human_analyst_feedback": "approve"
    })
    return {"report": result["final_report"]}
```

---

## üìö Extended Examples

### Business Research
```python
result = graph.invoke({
    "topic": "Market opportunities in sustainable packaging",
    "max_analysts": 5,
    "human_analyst_feedback": "Focus on B2B market segments and include cost analysis"
})
```

### Academic Research  
```python
result = graph.invoke({
    "topic": "Impact of quantum computing on cryptography",
    "max_analysts": 3,
    "human_analyst_feedback": "Include technical depth and timeline projections"
})
```

### Policy Research
```python
result = graph.invoke({
    "topic": "Effects of remote work policies on urban development", 
    "max_analysts": 4,
    "human_analyst_feedback": "Include international comparisons and economic data"
})
```

---

## ü§ù Contributing

### Development Setup
```bash
# Fork and clone
git clone https://github.com/yourusername/ai-research-assistant
cd ai-research-assistant

# Create development environment
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows
pip install -r requirements-dev.txt

# Run tests
pytest tests/
```

### Adding New Features

#### New Search Sources
1. Create search function following the pattern:
```python
def search_custom_source(state: InterviewState):
    # Implement search logic
    return {"context": [formatted_results]}
```

2. Add to interview graph:
```python
interview_builder.add_node("search_custom", search_custom_source)
interview_builder.add_edge("ask_question", "search_custom")
```

#### Custom Report Formats
1. Create formatter function:
```python
def format_executive_summary(state: ResearchGraphState):
    # Custom formatting logic
    return {"executive_summary": formatted_content}
```

2. Integrate into main graph:
```python
builder.add_node("create_executive_summary", format_executive_summary)
```

---

## üìÑ License & Credits

**MIT License** - Feel free to use, modify, and distribute.

**Built With:**
- ü¶ú [LangChain](https://langchain.com) - LLM framework
- üï∏Ô∏è [LangGraph](https://langgraph.com) - Multi-agent orchestration  
- ü§ñ [OpenAI GPT-4](https://openai.com) - Core language model
- üîç [Tavily](https://tavily.com) - Web search API
- üìä [Pydantic](https://pydantic.dev) - Data validation

**Acknowledgments:**
- LangChain team for the excellent multi-agent framework
- OpenAI for providing powerful language models
- Community contributors and feedback

---

## üìû Support & Contact

- **Issues:** [GitHub Issues](https://github.com/your-repo/issues)
- **Discussions:** [GitHub Discussions](https://github.com/your-repo/discussions)  
- **Email:** research-assistant@yourorg.com
- **Documentation:** [Full Documentation](https://docs.yourproject.com)

---

*Last Updated: August 2025*